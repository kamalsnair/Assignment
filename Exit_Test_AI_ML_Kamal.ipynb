{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN9rz3T2uC0Bxr3Jz2QIIio",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamalsnair/Assignment/blob/main/Exit_Test_AI_ML_Kamal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Problem Statement\n",
        "The 7 hills group of hospitals wants to bring in automation using artificial intelligence\n",
        "on X-rays in covid time. Pneumonia Detection is a binary classification problem\n",
        "where the goal is to classify chest X-ray images as either having pneumonia or not.\n",
        "The dataset for the competition contains over 26,000 chest X-ray images labeled as\n",
        "normal or pneumonia.\n",
        "you need to create a machine learning model that can accurately classify the chest Xray images as normal or pneumonia. The evaluation metric for the competition is the\n",
        "average precision score, which is a measure of how well the model can identify\n",
        "positive cases (pneumonia) while minimizing false positives (normal cases classified\n",
        "as pneumonia).\n",
        "Several deep learning models, such as convolutional neural networks (CNNs), can be\n",
        "use to solve this problem. To get started, you can explore the dataset, pre-process\n",
        "the images, and try building and training different models. "
      ],
      "metadata": {
        "id": "ybosAGoXm2EK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Required Libraries"
      ],
      "metadata": {
        "id": "dOnm13hrqL5V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mISrMI_djtSy"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Rectangle\n",
        "import seaborn as sns\n",
        "import gc\n",
        "import glob\n",
        "import os\n",
        "import cv2\n",
        "import warnings\n",
        "warnings.simplefilter(action = 'ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Specifing the Data Path in Google Drive"
      ],
      "metadata": {
        "id": "sFXcmg6DqZ87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "NaEmW45Lqa6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a426d35-4b06-4bbc-b3bf-d746fe50a2ac"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Train_labels = pd.read_csv('/content/drive/MyDrive/EXIT Test AI ML/rsna-pneumonia-detection-challenge/stage_2_train_images')\n",
        "Train_labels.head()"
      ],
      "metadata": {
        "id": "OQaXBcPXoDWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = Train_labels.groupby('Target').size()\n",
        "train_labels"
      ],
      "metadata": {
        "id": "QmXTdHd6oIJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Train_labels.shape"
      ],
      "metadata": {
        "id": "SgshEuqIoK2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels.plot.bar()"
      ],
      "metadata": {
        "id": "Ho1nMw18oNuZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Train_labels.fillna(0.0)"
      ],
      "metadata": {
        "id": "qMI85cmqoRwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = pd.read_csv('')\n",
        "sample.head()"
      ],
      "metadata": {
        "id": "0qSndZWjoUEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_info = pd.read_csv('')\n",
        "class_info.head()"
      ],
      "metadata": {
        "id": "hsH7G66znRHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_info.head()"
      ],
      "metadata": {
        "id": "KB74pHd3nX2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Class_info = class_info.groupby('class').size()\n",
        "Class_info"
      ],
      "metadata": {
        "id": "tRHgevBYodya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([Train_labels,class_info[\"class\"]],axis=1,sort=False)\n",
        "# df = pd.merge(left = detailed_df, right = train_df, how = 'left', on = 'patientId')\n",
        "df = df.drop_duplicates()\n",
        "df.info()"
      ],
      "metadata": {
        "id": "K3k-o0SqojV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "04Tj_5ososrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "Onc_RcIFoyzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Distribution of classes"
      ],
      "metadata": {
        "id": "kOXELch_o4yA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby('class').size()"
      ],
      "metadata": {
        "id": "ZkJCY4i3o1XC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"class\"].value_counts().plot(kind='pie',autopct='%1.0f%%', shadow=True, subplots=False)"
      ],
      "metadata": {
        "id": "VNSzuRCpo7w6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.pivot_table(df,index=[\"Target\"], aggfunc='count')"
      ],
      "metadata": {
        "id": "ywDpHBqzo-QC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x = 'class', hue = 'Target', data = df)"
      ],
      "metadata": {
        "id": "aKy1b-LlpA4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Correlation between the variables There is a strong Correlation between height and width variables"
      ],
      "metadata": {
        "id": "MO9sfseIpGI_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.corr()"
      ],
      "metadata": {
        "id": "LLd0V-13pDP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.jointplot(x = 'width', y = 'height', data = df, kind=\"reg\")"
      ],
      "metadata": {
        "id": "z-Yw4_lJpL7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EDA with the header values from the dataframe"
      ],
      "metadata": {
        "id": "6hWYIjIZpOs2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pydicom\n",
        "patientId = Train_labels['patientId'][0]\n",
        "dcm_file = '../input/rsna-pneumonia-detection-challenge/stage_2_train_images/%s.dcm'% patientId\n",
        "dcm_data = pydicom.read_file(dcm_file)\n",
        "\n",
        "print(dcm_data)"
      ],
      "metadata": {
        "id": "bKqAyAcTpPWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dicom_df=df\n",
        "dicom_df.shape"
      ],
      "metadata": {
        "id": "F_8NSabOpTrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "def process_dicom_data(data_df):\n",
        "    for n, pid in tqdm(enumerate(data_df['patientId'].unique())):        \n",
        "        dcm_file = '/kaggle/input/rsna-pneumonia-detection-challenge/stage_2_train_images/%s.dcm' % pid\n",
        "        dcm_data = pydicom.read_file(dcm_file)        \n",
        "        idx = (data_df['patientId']==dcm_data.PatientID)\n",
        "        data_df.loc[idx,'Modality'] = dcm_data.Modality\n",
        "        data_df.loc[idx,'PatientAge'] = pd.to_numeric(dcm_data.PatientAge)\n",
        "        data_df.loc[idx,'PatientSex'] = dcm_data.PatientSex\n",
        "        data_df.loc[idx,'BodyPartExamined'] = dcm_data.BodyPartExamined\n",
        "        data_df.loc[idx,'ViewPosition'] = dcm_data.ViewPosition\n",
        "        \n",
        "    return data_df"
      ],
      "metadata": {
        "id": "_Y63OEVdpXPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dicom_df = process_dicom_data(dicom_df)"
      ],
      "metadata": {
        "id": "UPgqzulppabx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dicom_df = dicom_df.astype({\"PatientAge\": int})\n",
        "dicom_df.fillna(0.0, inplace=True)\n",
        "dicom_df.head()"
      ],
      "metadata": {
        "id": "wgfL1nvPpdfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dicom_df.nunique()"
      ],
      "metadata": {
        "id": "QWzExShepzOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now Visualizing the data along with their dicom header values"
      ],
      "metadata": {
        "id": "st2iTNVAp6lv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (30, 10))\n",
        "sns.countplot(x = 'PatientAge', hue = 'Target', data = dicom_df)"
      ],
      "metadata": {
        "id": "WnKmM3x5p4WI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x = 'PatientSex', hue = 'Target', data = dicom_df)"
      ],
      "metadata": {
        "id": "CBh0DRrHp9xG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x = 'ViewPosition', hue = 'Target', data = dicom_df);"
      ],
      "metadata": {
        "id": "QnJOgY0AqCR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dicom_df = dicom_df.drop('Target', axis=1)"
      ],
      "metadata": {
        "id": "Drz_kI21qEov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dicom_df['PatientSex'].astype('category')\n",
        "dicom_df['ViewPosition'].astype('category')\n",
        "dicom_df['PatientSex'] = np.where(dicom_df[\"PatientSex\"].str.contains(\"M\"), 1, 0)\n",
        "dicom_df['ViewPosition'] = np.where(dicom_df[\"ViewPosition\"].str.contains(\"AP\"), 1, 0)"
      ],
      "metadata": {
        "id": "PlsO2_HXqGdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dicom_df.head()"
      ],
      "metadata": {
        "id": "w6VcB9jhqIN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dicom_df.corr()"
      ],
      "metadata": {
        "id": "t859Tw9PqKkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizing the dicom images"
      ],
      "metadata": {
        "id": "ZodJ0ZFOqNxg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_dicom_image(data_df):\n",
        "        img_data = list(data_df.T.to_dict().values())\n",
        "        f, ax = plt.subplots(2,2, figsize=(16,18))\n",
        "        for i,data_row in enumerate(img_data):\n",
        "            pid = data_row['patientId']\n",
        "            dcm_file = '/kaggle/input/rsna-pneumonia-detection-challenge/stage_2_train_images/%s.dcm' % pid\n",
        "            dcm_data = pydicom.read_file(dcm_file)                    \n",
        "            ax[i//2, i%2].imshow(dcm_data.pixel_array, cmap=plt.cm.bone)\n",
        "            ax[i//2, i%2].set_title('ID: {}\\n Age: {} Sex: {}'.format(\n",
        "                data_row['patientId'],dcm_data.PatientAge, dcm_data.PatientSex))"
      ],
      "metadata": {
        "id": "QcBG4M0nqNe_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_dicom_image(df[df['Target']==1].sample(n=4))"
      ],
      "metadata": {
        "id": "lkBVCarRqRVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Showing some random dicom images of a patient who do not have Pnuemonia, however with class No Lung Opacity / Not Normal"
      ],
      "metadata": {
        "id": "0jfXg23VqV1_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "show_dicom_image(df[ (df['Target']==0) & (df['class']=='No Lung Opacity / Not Normal')].sample(n=4))"
      ],
      "metadata": {
        "id": "8lNwZ882qTc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Showing some random dicom images of a patients who do not have Pnuemonia, however with class Normal"
      ],
      "metadata": {
        "id": "rQRMsIjKqbu3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "show_dicom_image(df[ (df['Target']==0) & (df['class']=='Normal')].sample(n=4))"
      ],
      "metadata": {
        "id": "mxzh2SCiqYZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now displaying images with bounding boxes"
      ],
      "metadata": {
        "id": "JIx4SzqQqgmQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_dicome_with_boundingbox(data_df):\n",
        "    img_data = list(data_df.T.to_dict().values())\n",
        "    f, ax = plt.subplots(2,2, figsize=(16,18))\n",
        "    for i,data_row in enumerate(img_data):\n",
        "        pid = data_row['patientId']\n",
        "        dcm_file = '/kaggle/input/rsna-pneumonia-detection-challenge/stage_2_train_images/%s.dcm' % pid\n",
        "        dcm_data = pydicom.read_file(dcm_file)                    \n",
        "        ax[i//2, i%2].imshow(dcm_data.pixel_array, cmap=plt.cm.bone)\n",
        "        ax[i//2, i%2].set_title('ID: {}\\n Age: {} Sex: {}'.format(\n",
        "                data_row['patientId'],dcm_data.PatientAge, dcm_data.PatientSex))\n",
        "        rows = data_df[data_df['patientId']==data_row['patientId']]\n",
        "        box_data = list(rows.T.to_dict().values())        \n",
        "        for j, row in enumerate(box_data):            \n",
        "            x,y,width,height = row['x'], row['y'],row['width'],row['height']\n",
        "            rectangle = Rectangle(xy=(x,y),width=width, height=height, color=\"red\",alpha = 0.1)\n",
        "            ax[i//2, i%2].add_patch(rectangle)   "
      ],
      "metadata": {
        "id": "71zsb24Oqjaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_dicome_with_boundingbox(df[df['Target']==1].sample(n=4))"
      ],
      "metadata": {
        "id": "XwWQaxjDqlxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Building"
      ],
      "metadata": {
        "id": "7wvp_F7ZqoZf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "import random\n",
        "import pydicom\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from skimage import measure\n",
        "from skimage.transform import resize\n",
        "import matplotlib.patches as patches\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "QtgOUvVAqpEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pneumonia_locations = {}\n",
        "# load table\n",
        "with open(os.path.join('/kaggle/input/rsna-pneumonia-detection-challenge/stage_2_train_labels.csv'), mode='r') as infile:\n",
        "    # open reader\n",
        "    reader = csv.reader(infile)\n",
        "    # skip header\n",
        "    next(reader, None)\n",
        "    # loop through rows\n",
        "    for rows in reader:\n",
        "        # retrieve information\n",
        "        filename = rows[0]\n",
        "        location = rows[1:5]\n",
        "        pneumonia = rows[5]\n",
        "        # if row contains pneumonia add label to dictionary\n",
        "        # which contains a list of pneumonia locations per filename\n",
        "        if pneumonia == '1':\n",
        "            # convert string to float to int\n",
        "            location = [int(float(i)) for i in location]\n",
        "            # save pneumonia location in dictionary\n",
        "            if filename in pneumonia_locations:\n",
        "                pneumonia_locations[filename].append(location)\n",
        "            else:\n",
        "                pneumonia_locations[filename] = [location]"
      ],
      "metadata": {
        "id": "pVe-MwvZqrcr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load image filenames"
      ],
      "metadata": {
        "id": "mhvg_KJRqxpq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load and shuffle filenames\n",
        "folder = '/kaggle/input/rsna-pneumonia-detection-challenge/stage_2_train_images'\n",
        "filenames = os.listdir(folder)\n",
        "random.shuffle(filenames)\n",
        "# split into train and validation filenames\n",
        "n_valid_samples = 8000\n",
        "train_filenames = filenames[n_valid_samples:]\n",
        "valid_filenames = filenames[:n_valid_samples]\n",
        "print('n train samples', len(train_filenames))\n",
        "print('n valid samples', len(valid_filenames))\n",
        "n_train_samples = len(filenames) - n_valid_samples"
      ],
      "metadata": {
        "id": "ciJbu1rgqvNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data generator\n",
        "\n",
        "The dataset is too large to fit into memory, so we need to create a generator that loads data on the fly.\n",
        "\n",
        "The generator takes in some filenames, batch_size and other parameters.\n",
        "\n",
        "The generator outputs a random batch of numpy images and numpy masks."
      ],
      "metadata": {
        "id": "FhG_zbJGq6z2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class generator(keras.utils.Sequence):    \n",
        "    def __init__(self, folder, filenames, pneumonia_locations=None, batch_size=32, image_size=256, shuffle=True, augment=False, predict=False):\n",
        "        self.folder = folder\n",
        "        self.filenames = filenames\n",
        "        self.pneumonia_locations = pneumonia_locations\n",
        "        self.batch_size = batch_size\n",
        "        self.image_size = image_size\n",
        "        self.shuffle = shuffle\n",
        "        self.augment = augment\n",
        "        self.predict = predict\n",
        "        self.on_epoch_end()\n",
        "        \n",
        "    def __load__(self, filename):\n",
        "        # load dicom file as numpy array\n",
        "        img = pydicom.dcmread(os.path.join(self.folder, filename)).pixel_array\n",
        "        # create empty mask\n",
        "        msk = np.zeros(img.shape)\n",
        "        # get filename without extension\n",
        "        filename = filename.split('.')[0]\n",
        "        # if image contains pneumonia\n",
        "        if filename in self.pneumonia_locations:\n",
        "            # loop through pneumonia\n",
        "            for location in self.pneumonia_locations[filename]:\n",
        "                # add 1's at the location of the pneumonia\n",
        "                x, y, w, h = location\n",
        "                msk[y:y+h, x:x+w] = 1\n",
        "        # resize both image and mask\n",
        "        img = resize(img, (self.image_size, self.image_size), mode='reflect')\n",
        "        msk = resize(msk, (self.image_size, self.image_size), mode='reflect') > 0.5\n",
        "        # if augment then horizontal flip half the time\n",
        "        if self.augment and random.random() > 0.5:\n",
        "            img = np.fliplr(img)\n",
        "            msk = np.fliplr(msk)\n",
        "        # add trailing channel dimension\n",
        "        img = np.expand_dims(img, -1)\n",
        "        msk = np.expand_dims(msk, -1)\n",
        "        return img, msk\n",
        "    \n",
        "    def __loadpredict__(self, filename):\n",
        "        # load dicom file as numpy array\n",
        "        img = pydicom.dcmread(os.path.join(self.folder, filename)).pixel_array\n",
        "        # resize image\n",
        "        img = resize(img, (self.image_size, self.image_size), mode='reflect')\n",
        "        # add trailing channel dimension\n",
        "        img = np.expand_dims(img, -1)\n",
        "        return img\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        # select batch\n",
        "        filenames = self.filenames[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        # predict mode: return images and filenames\n",
        "        if self.predict:\n",
        "            # load files\n",
        "            imgs = [self.__loadpredict__(filename) for filename in filenames]\n",
        "            # create numpy batch\n",
        "            imgs = np.array(imgs)\n",
        "            return imgs, filenames\n",
        "        # train mode: return images and masks\n",
        "        else:\n",
        "            # load files\n",
        "            items = [self.__load__(filename) for filename in filenames]\n",
        "            # unzip images and masks\n",
        "            imgs, msks = zip(*items)\n",
        "            # create numpy batch\n",
        "            imgs = np.array(imgs)\n",
        "            msks = np.array(msks)\n",
        "            return imgs, msks\n",
        "        \n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            random.shuffle(self.filenames)\n",
        "        \n",
        "    def __len__(self):\n",
        "        if self.predict:\n",
        "            # return everything\n",
        "            return int(np.ceil(len(self.filenames) / self.batch_size))\n",
        "        else:\n",
        "            # return full batches only\n",
        "            return int(len(self.filenames) / self.batch_size)"
      ],
      "metadata": {
        "id": "BuPFYb6_q7a-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define iou or jaccard loss function\n",
        "def iou_loss(y_true, y_pred):\n",
        "    #print(y_true)\n",
        "    y_true=tf.cast(y_true, tf.float32)\n",
        "    y_pred=tf.cast(y_pred, tf.float32)\n",
        "    y_true = tf.reshape(y_true, [-1])\n",
        "    y_pred = tf.reshape(y_pred, [-1])\n",
        "   \n",
        "    intersection = tf.reduce_sum(y_true * y_pred)\n",
        "    score = (intersection + 1.) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) - intersection + 1.)\n",
        "    return 1 - score\n",
        "\n",
        "# combine bce loss and iou loss\n",
        "def iou_bce_loss(y_true, y_pred):\n",
        "    return 0.5 * keras.losses.binary_crossentropy(y_true, y_pred) + 0.5 * iou_loss(y_true, y_pred)\n",
        "\n",
        "# mean iou as a metric\n",
        "def mean_iou(y_true, y_pred):\n",
        "    y_pred = tf.round(y_pred)\n",
        "    intersect = tf.reduce_sum(y_true * y_pred, axis=[1, 2, 3])\n",
        "    union = tf.reduce_sum(y_true, axis=[1, 2, 3]) + tf.reduce_sum(y_pred, axis=[1, 2, 3])\n",
        "    smooth = tf.ones(tf.shape(intersect))\n",
        "    return tf.reduce_mean((intersect + smooth) / (union - intersect + smooth))\n",
        "\n",
        "def create_downsample(channels, inputs):\n",
        "    x = keras.layers.BatchNormalization(momentum=0.9)(inputs)\n",
        "    x = keras.layers.LeakyReLU(0)(x)\n",
        "    x = keras.layers.Conv2D(channels, 1, padding='same', use_bias=False)(x)\n",
        "    x = keras.layers.MaxPool2D(2)(x)\n",
        "    return x\n",
        "\n",
        "def create_resblock(channels, inputs):\n",
        "    x = keras.layers.BatchNormalization(momentum=0.9)(inputs)\n",
        "    x = keras.layers.LeakyReLU(0)(x)\n",
        "    x = keras.layers.Conv2D(channels, 3, padding='same', use_bias=False)(x)\n",
        "    x = keras.layers.BatchNormalization(momentum=0.9)(x)\n",
        "    x = keras.layers.LeakyReLU(0)(x)\n",
        "    x = keras.layers.Conv2D(channels, 3, padding='same', use_bias=False)(x)\n",
        "    return keras.layers.add([x, inputs])\n",
        "\n",
        "def create_network(input_size, channels, n_blocks=2, depth=4):\n",
        "    # input\n",
        "    inputs = keras.Input(shape=(input_size, input_size, 1))\n",
        "    x = keras.layers.Conv2D(channels, 3, padding='same', use_bias=False)(inputs)\n",
        "    # residual blocks\n",
        "    for d in range(depth):\n",
        "        channels = channels * 2\n",
        "        x = create_downsample(channels, x)\n",
        "        for b in range(n_blocks):\n",
        "            x = create_resblock(channels, x)\n",
        "    # output\n",
        "    x = keras.layers.BatchNormalization(momentum=0.9)(x)\n",
        "    x = keras.layers.LeakyReLU(0)(x)\n",
        "    x = keras.layers.Conv2D(1, 1, activation='sigmoid')(x)\n",
        "    outputs = keras.layers.UpSampling2D(2**depth)(x)\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "metadata": {
        "id": "jcLcmX12rAgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_network(input_size=IMAGE_SIZE, channels=32, n_blocks=2, depth=4)\n",
        "model.compile(optimizer='adam', loss=iou_bce_loss, metrics=['accuracy', mean_iou])\n",
        "\n",
        "# cosine learning rate annealing\n",
        "def cosine_annealing(x):\n",
        "    lr = 0.0001\n",
        "    epochs = 3\n",
        "    return lr*(np.cos(np.pi*x/epochs)+1.)/2\n",
        "\n",
        "\n",
        "learning_rate = tf.keras.callbacks.LearningRateScheduler(cosine_annealing)\n",
        "\n",
        "# create train and validation generators\n",
        "folder = '/kaggle/input/rsna-pneumonia-detection-challenge/stage_2_train_images'\n",
        "train_gen = generator(folder, train_filenames, pneumonia_locations, batch_size=BATCH_SIZE, image_size=IMAGE_SIZE, shuffle=True, augment=False, predict=False)\n",
        "valid_gen = generator(folder, valid_filenames, pneumonia_locations, batch_size=BATCH_SIZE, image_size=IMAGE_SIZE, shuffle=False, predict=False)\n",
        "\n",
        "print(model.summary())"
      ],
      "metadata": {
        "id": "vi5w0fG8rFLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot Accuracy / Loss"
      ],
      "metadata": {
        "id": "E_hV9Z89rO-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,4))\n",
        "plt.subplot(131)\n",
        "plt.plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\n",
        "plt.plot(history.epoch, history.history[\"val_loss\"], label=\"Valid loss\")\n",
        "plt.legend()\n",
        "plt.subplot(132)\n",
        "plt.plot(history.epoch, history.history[\"accuracy\"], label=\"Train accuracy\")\n",
        "plt.plot(history.epoch, history.history[\"val_accuracy\"], label=\"Valid accuracy\")\n",
        "plt.legend()\n",
        "plt.subplot(133)\n",
        "plt.plot(history.epoch, history.history[\"mean_iou\"], label=\"Train iou\")\n",
        "plt.plot(history.epoch, history.history[\"val_mean_iou\"], label=\"Valid iou\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "0VWfU0AtrJ82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predict test images"
      ],
      "metadata": {
        "id": "OjSPQRWgrUEP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i=0\n",
        "for imgs, msks in valid_gen:    \n",
        "    # predict batch of images\n",
        "    preds = model.predict(imgs)\n",
        "    # create figure\n",
        "    f, axarr = plt.subplots(4, 8, figsize=(20,15))\n",
        "    axarr = axarr.ravel()\n",
        "    axidx = 0\n",
        "    # loop through batch\n",
        "    for img, msk, pred in zip(imgs, msks, preds):\n",
        "        i=i+1\n",
        "        #exit after 32 images\n",
        "        if i>32:\n",
        "            break\n",
        "        # plot image\n",
        "        axarr[axidx].imshow(img[:, :, 0])\n",
        "        # threshold true mask\n",
        "        comp = msk[:, :, 0] > 0.5\n",
        "        # apply connected components\n",
        "        comp = measure.label(comp)\n",
        "        # apply bounding boxes\n",
        "        predictionString = ''\n",
        "        for region in measure.regionprops(comp):\n",
        "            # retrieve x, y, height and width\n",
        "            y, x, y2, x2 = region.bbox\n",
        "            height = y2 - y\n",
        "            width = x2 - x\n",
        "            axarr[axidx].add_patch(patches.Rectangle((x,y),width,height,linewidth=2,edgecolor='b',facecolor='none'))\n",
        "        # threshold predicted mask\n",
        "        comp = pred[:, :, 0] > 0.5\n",
        "        # apply connected components\n",
        "        comp = measure.label(comp)\n",
        "        # apply bounding boxes\n",
        "        predictionString = ''\n",
        "        for region in measure.regionprops(comp):\n",
        "            # retrieve x, y, height and width\n",
        "            y, x, y2, x2 = region.bbox\n",
        "            height = y2 - y\n",
        "            width = x2 - x\n",
        "            axarr[axidx].add_patch(patches.Rectangle((x,y),width,height,linewidth=2,edgecolor='r',facecolor='none'))\n",
        "        axidx += 1\n",
        "    plt.show()\n",
        "    # only plot one batch\n",
        "    break\n"
      ],
      "metadata": {
        "id": "W2AFUXcorSFl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder = '/kaggle/input/rsna-pneumonia-detection-challenge/stage_2_test_images'\n",
        "test_filenames = os.listdir(folder)\n",
        "print('n test samples:', len(test_filenames))\n",
        "\n",
        "# create test generator with predict flag set to True\n",
        "test_gen = generator(folder, test_filenames, None, batch_size=100, image_size=128, shuffle=False, predict=True)\n",
        "\n",
        "# create submission dictionary\n",
        "submission_dict = {}\n",
        "# loop through testset\n",
        "for imgs, filenames in tqdm(test_gen):\n",
        "    # predict batch of images\n",
        "    preds = model.predict(imgs)\n",
        "    # loop through batch\n",
        "    for pred, filename in zip(preds, filenames):\n",
        "        # resize predicted mask\n",
        "        pred = resize(pred, (1024, 1024), mode='reflect')\n",
        "        # threshold predicted mask\n",
        "        comp = pred[:, :, 0] > 0.5\n",
        "        # apply connected components\n",
        "        comp = measure.label(comp)\n",
        "        # apply bounding boxes\n",
        "        predictionString = ''\n",
        "        for region in measure.regionprops(comp):\n",
        "            # retrieve x, y, height and width\n",
        "            y, x, y2, x2 = region.bbox\n",
        "            height = y2 - y\n",
        "            width = x2 - x\n",
        "            # proxy for confidence score\n",
        "            conf = np.mean(pred[y:y+height, x:x+width])\n",
        "            # add to predictionString\n",
        "            predictionString += str(conf) + ' ' + str(x) + ' ' + str(y) + ' ' + str(width) + ' ' + str(height) + ' '\n",
        "        # add filename and predictionString to dictionary\n",
        "        filename = filename.split('.')[0]\n",
        "        submission_dict[filename] = predictionString\n",
        "    # stop if we've got them all\n",
        "    if len(submission_dict) >= len(test_filenames):\n",
        "        break\n",
        "\n",
        "# save dictionary as csv file\n",
        "sub = pd.DataFrame.from_dict(submission_dict,orient='index')\n",
        "sub.index.names = ['patientId']\n",
        "sub.columns = ['PredictionString']\n",
        "sub.to_csv('submission.csv')"
      ],
      "metadata": {
        "id": "-PK5sS07rYwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load and shuffle filenames\n",
        "#folder = '../input/stage_2_test_images'\n",
        "#test_filenames = os.listdir(folder)\n",
        "#print('n test samples:', len(test_filenames))\n",
        "\n",
        "# create test generator with predict flag set to True\n",
        "\n",
        "folder = '/kaggle/input/rsna-pneumonia-detection-challenge/stage_2_test_images'\n",
        "#train_gen = generator(folder, train_filenames, pneumonia_locations, batch_size=BATCH_SIZE, image_size=IMAGE_SIZE, shuffle=True, augment=True, predict=False)\n",
        "#test_gen = generator(folder, valid_filenames, None, batch_size=32, image_size=IMAGE_SIZE, shuffle=False, predict=True)\n",
        "test_gen = generator(folder, test_filenames, None, batch_size=32, image_size=128, shuffle=False, predict=True)\n",
        "\n",
        "# create submission dictionary\n",
        "submission_dict = {}\n",
        "# loop through testset\n",
        "for imgs, filenames in test_gen:\n",
        "    # predict batch of images\n",
        "    preds = model.predict(imgs)\n",
        "    # loop through batch\n",
        "    for pred, filename in zip(preds, filenames):\n",
        "       # print(filename)\n",
        "        # resize predicted mask\n",
        "        pred = resize(pred, (1024, 1024), mode='reflect')\n",
        "        # threshold predicted mask\n",
        "        comp = pred[:, :, 0] > 0.5\n",
        "        # apply connected components\n",
        "        comp = measure.label(comp)\n",
        "        # apply bounding boxes\n",
        "        predictionString = ''\n",
        "        for region in measure.regionprops(comp):\n",
        "            # retrieve x, y, height and width\n",
        "            y, x, y2, x2 = region.bbox\n",
        "            height = y2 - y\n",
        "            width = x2 - x\n",
        "            # proxy for confidence score\n",
        "            conf = np.mean(pred[y:y+height, x:x+width])\n",
        "            # add to predictionString\n",
        "            predictionString += str(conf) + ' ' + str(x) + ' ' + str(y) + ' ' + str(width) + ' ' + str(height) + ' '\n",
        "        # add filename and predictionString to dictionary\n",
        "        filename = filename.split('.')[0]\n",
        "        submission_dict[filename] = predictionString\n",
        "    # stop if we've got them all\n",
        "    if len(submission_dict) >= len(test_filenames):\n",
        "        break\n",
        "        \n",
        "print(\"Done predicting...\")\n",
        "        \n",
        "# save dictionary as csv file\n",
        "sub = pd.DataFrame.from_dict(submission_dict,orient='index')\n",
        "sub.index.names = ['patientId']\n",
        "sub.columns = ['PredictionString']\n",
        "sub.to_csv('submission.csv')"
      ],
      "metadata": {
        "id": "8fe1RjvtreF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6Qt2VpIHri-F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}